# Marugoto Grammar Graph System
## Comprehensive Documentation & Integration Guide

### üéØ **Overview**

The Marugoto Grammar Graph System is a sophisticated knowledge representation of Japanese grammar patterns from the Marugoto textbook series. It provides a rich, interconnected graph database that powers intelligent language learning features in the AI Language Tutor application.

---

## üìä **System Architecture**

### **Data Model**

The system consists of **6 primary node types** and **9 relationship types** creating a comprehensive learning graph:

#### **Node Types**
```cypher
// 1. GrammarPattern - Core grammar points (392 nodes)
(:GrammarPattern {
    id: "grammar_001",
    sequence_number: 1,
    pattern: "ÔΩû„ÅØÔΩû„Åß„Åô",                    // Original Japanese pattern
    pattern_romaji: "~wa~desu",              // Romanized version
    textbook_form: "N1„ÅØN2„Åß„ÅôÔºà„ÅãÔºâ",        // Textbook explanation
    textbook_form_romaji: "N1 wa N2 desu (ka)",
    example_sentence: "ÁßÅ„ÅØ„Ç´„Éº„É©„Åß„Åô„ÄÇ",      // Example usage
    example_romaji: "Watashi wa Kaara desu.",
    classification: "Ë™¨Êòé",                   // Functional classification
    textbook: "ÂÖ•ÈñÄ(„Çä„Åã„ÅÑ)",                 // Textbook level
    topic: "„Çè„Åü„Åó",                         // Chapter topic
    lesson: "„Å©„ÅÜ„Åû„Çà„Çç„Åó„Åè",                // Lesson name
    jfs_category: "Ëá™ÂàÜ„Å®ÂÆ∂Êóè",              // JFS topic category
    created_at: datetime(),
    status: "approved",
    source: "marugoto_grammar_list"
})

// 2. TextbookLevel - Learning progression levels (6 nodes)
(:TextbookLevel {
    id: "nyumon_rikai",
    name: "ÂÖ•ÈñÄ(„Çä„Åã„ÅÑ)",
    level_order: 1,
    description: "Beginner comprehension level"
})

// 3. GrammarClassification - Function types (63 nodes)
(:GrammarClassification {
    id: "setsumei",
    name: "Ë™¨Êòé",
    description: "Explanation/description patterns"
})

// 4. JFSCategory - Japan Foundation Standard categories (25 nodes)
(:JFSCategory {
    id: "jibun_kazoku",
    name: "Ëá™ÂàÜ„Å®ÂÆ∂Êóè",
    description: "Self and family"
})

// 5. MarugotoTopic - Chapter topics (55 nodes)
(:MarugotoTopic {
    id: "watashi",
    name: "„Çè„Åü„Åó",
    description: "About myself"
})

// 6. Word - Existing vocabulary nodes (138,153 nodes)
(:Word {
    kanji: "ÁßÅ",
    hiragana: "„Çè„Åü„Åó",
    translation: "I, me"
    // ... other word properties
})
```

#### **Relationship Types**
```cypher
// Core Learning Relationships
(g:GrammarPattern)-[:BELONGS_TO_LEVEL]->(t:TextbookLevel)          // 392 relationships
(g:GrammarPattern)-[:HAS_CLASSIFICATION]->(gc:GrammarClassification) // 392 relationships
(g:GrammarPattern)-[:CATEGORIZED_AS]->(jfs:JFSCategory)            // 392 relationships

// Vocabulary Integration
(g:GrammarPattern)-[:USES_WORD]->(w:Word)                          // 2,046 relationships

// Learning Progression
(g1:GrammarPattern)-[:PREREQUISITE_FOR]->(g2:GrammarPattern)       // 3,654 relationships
(g1:GrammarPattern)-[:SIMILAR_TO]->(g2:GrammarPattern)             // 4,448 relationships

// Hierarchical Structure
(topic:MarugotoTopic)-[:PART_OF]->(level:TextbookLevel)
(lesson:MarugotoLesson)-[:PART_OF]->(topic:MarugotoTopic)
(g:GrammarPattern)-[:TAUGHT_IN_LESSON]->(lesson:MarugotoLesson)
```

### **Statistics Summary**
- **Total Nodes**: 138,691
- **Total Relationships**: 185,817
- **Grammar Patterns**: 392 (from 6 textbook levels)
- **Vocabulary Connections**: 2,046
- **Learning Paths**: 3,654 prerequisite relationships
- **Similarity Connections**: 4,448

---

## üõ†Ô∏è **Implementation Files**

### **Core Import Scripts**
```
resources/
‚îú‚îÄ‚îÄ marugoto_grammar_importer_fast.py     # Main import script (no AI validation)
‚îú‚îÄ‚îÄ marugoto_grammar_importer.py          # Full import script (with AI validation)
‚îú‚îÄ‚îÄ add_core_relationships.py             # Relationship enhancement script
‚îî‚îÄ‚îÄ enhance_grammar_relationships.py      # Advanced relationship builder
```

### **Testing & Validation**
```
resources/
‚îú‚îÄ‚îÄ test_marugoto_graph.py                # Basic graph validation
‚îú‚îÄ‚îÄ test_enhanced_grammar_queries.py      # Advanced query testing
‚îî‚îÄ‚îÄ setup_marugoto_import.py              # Environment setup checker
```

### **Data Source**
```
resources/
‚îî‚îÄ‚îÄ list_of_grammar_and_sentence_patterns (1).xlsx - ÊñáÊ≥ï„ÉªÊñáÂûã„É™„Çπ„Éà.tsv
    # 394 rows of grammar patterns from Marugoto textbook series
```

---

## üîß **Installation & Setup**

### **Prerequisites**
```bash
# Required Python packages
pip install pandas pykakasi neo4j python-dotenv google-generativeai

# Environment variables (.env file)
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_password
GEMINI_API_KEY=your_gemini_key  # Optional for AI validation
```

### **Quick Setup**
```powershell
# 1. Check environment
python resources\setup_marugoto_import.py

# 2. Run fast import (recommended)
python resources\marugoto_grammar_importer_fast.py

# 3. Add relationships
python resources\add_core_relationships.py

# 4. Validate results
python resources\test_enhanced_grammar_queries.py
```

---

## üöÄ **API Integration**

### **Recommended Backend Endpoints**

```python
# backend/app/api/v1/endpoints/grammar.py

@router.get("/grammar/patterns")
async def get_grammar_patterns(
    level: Optional[str] = None,
    classification: Optional[str] = None,
    jfs_category: Optional[str] = None,
    limit: int = 20
):
    """Get grammar patterns with optional filtering"""

@router.get("/grammar/patterns/{pattern_id}/similar")
async def get_similar_patterns(pattern_id: str, limit: int = 5):
    """Get patterns similar to the specified pattern"""

@router.get("/grammar/patterns/{pattern_id}/prerequisites")
async def get_prerequisites(pattern_id: str):
    """Get prerequisite patterns for learning progression"""

@router.get("/grammar/learning-path")
async def get_learning_path(
    from_pattern: str,
    to_level: str,
    max_depth: int = 3
):
    """Generate a learning path between patterns/levels"""

@router.get("/grammar/patterns/by-word/{word}")
async def get_patterns_by_word(word: str):
    """Get grammar patterns that use a specific word"""

@router.get("/grammar/recommendations")
async def get_pattern_recommendations(
    user_level: str,
    known_patterns: List[str] = []
):
    """Get personalized pattern recommendations"""
```

### **Service Layer Implementation**

```python
# backend/app/services/grammar_service.py

class GrammarService:
    def __init__(self, neo4j_session):
        self.session = neo4j_session
    
    async def get_learning_path(self, from_pattern: str, to_level: str) -> List[Dict]:
        """Generate optimal learning path"""
        query = """
        MATCH path = (start:GrammarPattern {id: $from_pattern})
                    -[:PREREQUISITE_FOR*1..3]->
                    (end:GrammarPattern)-[:BELONGS_TO_LEVEL]->
                    (level:TextbookLevel {name: $to_level})
        RETURN path
        ORDER BY length(path)
        LIMIT 5
        """
        result = await self.session.run(query, from_pattern=from_pattern, to_level=to_level)
        return [record["path"] for record in result]
    
    async def get_similar_patterns(self, pattern_id: str, limit: int = 5) -> List[Dict]:
        """Find similar patterns for comparison learning"""
        query = """
        MATCH (p:GrammarPattern {id: $pattern_id})-[s:SIMILAR_TO]->(similar:GrammarPattern)
        RETURN similar.pattern, similar.pattern_romaji, similar.example_sentence, 
               similar.textbook, s.reason
        ORDER BY similar.sequence_number
        LIMIT $limit
        """
        result = await self.session.run(query, pattern_id=pattern_id, limit=limit)
        return [dict(record) for record in result]
    
    async def get_vocabulary_patterns(self, word: str) -> List[Dict]:
        """Get patterns using specific vocabulary"""
        query = """
        MATCH (w:Word)-[:APPEARS_IN_EXAMPLE]-(g:GrammarPattern)
        WHERE w.kanji = $word OR w.hiragana = $word
        RETURN g.pattern, g.pattern_romaji, g.example_sentence, g.textbook
        ORDER BY g.sequence_number
        """
        result = await self.session.run(query, word=word)
        return [dict(record) for record in result]
```

---

## üé® **Frontend Integration**

### **React Components**

```typescript
// frontend/src/components/grammar/GrammarPatternCard.tsx
interface GrammarPattern {
  id: string;
  pattern: string;
  patternRomaji: string;
  exampleSentence: string;
  exampleRomaji: string;
  classification: string;
  textbook: string;
  jfsCategory: string;
}

export const GrammarPatternCard: React.FC<{pattern: GrammarPattern}> = ({pattern}) => {
  return (
    <Card className="grammar-pattern-card">
      <CardHeader>
        <div className="flex justify-between items-center">
          <h3 className="text-xl font-bold">{pattern.pattern}</h3>
          <Badge variant="secondary">{pattern.textbook}</Badge>
        </div>
        <p className="text-muted-foreground">{pattern.patternRomaji}</p>
      </CardHeader>
      <CardContent>
        <div className="space-y-2">
          <div>
            <p className="font-medium">Example:</p>
            <p className="text-lg">{pattern.exampleSentence}</p>
            <p className="text-sm text-muted-foreground">{pattern.exampleRomaji}</p>
          </div>
          <div className="flex gap-2">
            <Badge variant="outline">{pattern.classification}</Badge>
            <Badge variant="outline">{pattern.jfsCategory}</Badge>
          </div>
        </div>
      </CardContent>
    </Card>
  );
};
```

```typescript
// frontend/src/components/grammar/LearningPathVisualization.tsx
export const LearningPathVisualization: React.FC<{
  patterns: GrammarPattern[];
  relationships: Array<{from: string; to: string; type: string}>;
}> = ({patterns, relationships}) => {
  // Use React Flow or similar library for graph visualization
  return (
    <div className="learning-path-graph">
      {/* Interactive graph showing learning progression */}
    </div>
  );
};
```

### **Page Components**

```typescript
// frontend/src/app/grammar/page.tsx
export default function GrammarPage() {
  const [selectedLevel, setSelectedLevel] = useState<string>('');
  const [patterns, setPatterns] = useState<GrammarPattern[]>([]);
  
  return (
    <div className="grammar-page">
      <div className="filters">
        <Select value={selectedLevel} onValueChange={setSelectedLevel}>
          <SelectTrigger>
            <SelectValue placeholder="Select Level" />
          </SelectTrigger>
          <SelectContent>
            <SelectItem value="ÂÖ•ÈñÄ(„Çä„Åã„ÅÑ)">ÂÖ•ÈñÄ (Beginner)</SelectItem>
            <SelectItem value="ÂàùÁ¥ö1(„Çä„Åã„ÅÑ)">ÂàùÁ¥ö1 (Elementary 1)</SelectItem>
            {/* ... more levels */}
          </SelectContent>
        </Select>
      </div>
      
      <div className="patterns-grid">
        {patterns.map(pattern => (
          <GrammarPatternCard key={pattern.id} pattern={pattern} />
        ))}
      </div>
    </div>
  );
}
```

---

## üìö **Usage Examples**

### **Common Query Patterns**

```cypher
-- 1. Get all patterns for a specific level
MATCH (g:GrammarPattern)-[:BELONGS_TO_LEVEL]->(t:TextbookLevel {name: 'ÂÖ•ÈñÄ(„Çä„Åã„ÅÑ)'})
RETURN g
ORDER BY g.sequence_number;

-- 2. Find learning prerequisites
MATCH path = (basic:GrammarPattern {pattern: 'ÔΩû„ÅØÔΩû„Åß„Åô'})-[:PREREQUISITE_FOR*1..2]->(advanced)
RETURN path;

-- 3. Get similar patterns for comparison
MATCH (g1:GrammarPattern {id: 'grammar_001'})-[:SIMILAR_TO]->(g2:GrammarPattern)
RETURN g1.pattern, g2.pattern, g2.textbook;

-- 4. Find patterns using specific vocabulary
MATCH (w:Word {kanji: 'ÁßÅ'})<-[:USES_WORD]-(g:GrammarPattern)
RETURN g.pattern, g.example_sentence
ORDER BY g.sequence_number;

-- 5. Get patterns by functional classification
MATCH (g:GrammarPattern)-[:HAS_CLASSIFICATION]->(gc:GrammarClassification {name: 'Ë™¨Êòé'})
RETURN g.pattern, g.textbook;

-- 6. Learning path recommendation
MATCH (user_pattern:GrammarPattern {textbook: 'ÂÖ•ÈñÄ(„Çä„Åã„ÅÑ)'})
MATCH (user_pattern)-[:PREREQUISITE_FOR]->(next_pattern:GrammarPattern)
WHERE next_pattern.textbook = 'ÂàùÁ¥ö1(„Çä„Åã„ÅÑ)'
RETURN next_pattern
ORDER BY next_pattern.sequence_number;
```

### **AI Chat Integration Examples**

```python
# Example: Grammar pattern explanation with context
async def explain_grammar_pattern(pattern: str, user_level: str) -> str:
    # Get pattern details
    pattern_data = await grammar_service.get_pattern_details(pattern)
    
    # Get similar patterns for comparison
    similar_patterns = await grammar_service.get_similar_patterns(pattern_data.id)
    
    # Get prerequisite knowledge
    prerequisites = await grammar_service.get_prerequisites(pattern_data.id)
    
    # Generate AI explanation with context
    context = {
        "pattern": pattern_data,
        "similar_patterns": similar_patterns,
        "prerequisites": prerequisites,
        "user_level": user_level
    }
    
    return await ai_service.generate_grammar_explanation(context)

# Example: Personalized learning recommendations
async def get_next_patterns_to_learn(user_id: str) -> List[GrammarPattern]:
    # Get user's known patterns
    known_patterns = await user_service.get_known_patterns(user_id)
    
    # Find patterns that have prerequisites met
    next_patterns = await grammar_service.get_learnable_patterns(
        known_patterns=known_patterns,
        user_level=await user_service.get_user_level(user_id)
    )
    
    return next_patterns
```

---

## üîç **Advanced Features**

### **1. Adaptive Learning Paths**
```python
def generate_adaptive_path(user_profile: UserProfile) -> LearningPath:
    """Generate personalized learning sequence based on user's strengths/weaknesses"""
    # Use graph algorithms to find optimal progression
    # Consider user's vocabulary knowledge, grammar mastery, and learning preferences
```

### **2. Pattern Comparison Tool**
```python
def compare_patterns(pattern1_id: str, pattern2_id: str) -> ComparisonResult:
    """Generate detailed comparison between similar patterns"""
    # Highlight differences, provide usage contexts, show examples
```

### **3. Vocabulary-Grammar Integration**
```python
def get_grammar_for_vocabulary(words: List[str]) -> List[GrammarPattern]:
    """Find grammar patterns that use specific vocabulary"""
    # Help users learn grammar in context of words they know
```

### **4. Cultural Context Integration**
```python
def get_cultural_context(pattern_id: str) -> CulturalContext:
    """Provide cultural usage context for grammar patterns"""
    # Link to JFS categories and real-world usage scenarios
```

---

## üìà **Performance Considerations**

### **Indexing Strategy**
```cypher
-- Essential indexes for performance
CREATE INDEX pattern_sequence IF NOT EXISTS FOR (g:GrammarPattern) ON (g.sequence_number);
CREATE INDEX pattern_textbook IF NOT EXISTS FOR (g:GrammarPattern) ON (g.textbook);
CREATE INDEX pattern_classification IF NOT EXISTS FOR (g:GrammarPattern) ON (g.classification);
CREATE INDEX word_kanji IF NOT EXISTS FOR (w:Word) ON (w.kanji);
CREATE INDEX word_hiragana IF NOT EXISTS FOR (w:Word) ON (w.hiragana);
```

### **Query Optimization**
- Use `LIMIT` clauses for paginated results
- Index frequently queried properties
- Consider caching common query results
- Use relationship direction for better performance

### **Caching Strategy**
```python
# Cache frequently accessed data
@cache(expire=3600)  # 1 hour cache
async def get_level_patterns(level: str) -> List[GrammarPattern]:
    """Cached retrieval of patterns by level"""
    
@cache(expire=86400)  # 24 hour cache
async def get_pattern_relationships(pattern_id: str) -> Dict:
    """Cached relationship data"""
```

---

## üß™ **Testing & Validation**

### **Test Coverage**
- ‚úÖ Data import validation (392/392 patterns imported)
- ‚úÖ Relationship integrity (185,817 total relationships)
- ‚úÖ Query performance testing
- ‚úÖ API endpoint testing
- ‚úÖ Frontend component testing

### **Validation Queries**
```cypher
-- Verify data integrity
MATCH (g:GrammarPattern) 
WHERE g.pattern IS NULL OR g.example_sentence IS NULL
RETURN count(g) AS invalid_patterns;

-- Check relationship consistency
MATCH (g:GrammarPattern)-[:PREREQUISITE_FOR]->(advanced:GrammarPattern)
WHERE g.sequence_number >= advanced.sequence_number
RETURN count(*) AS invalid_prerequisites;
```

---

## üöÄ **Deployment Checklist**

### **Backend Integration**
- [ ] Add grammar service to dependency injection
- [ ] Implement API endpoints
- [ ] Add authentication/authorization
- [ ] Set up caching layer
- [ ] Configure logging and monitoring

### **Frontend Integration**
- [ ] Create grammar learning components
- [ ] Implement pattern visualization
- [ ] Add learning path features
- [ ] Integrate with existing UI components
- [ ] Add responsive design

### **Database**
- [ ] Verify Neo4j indexes
- [ ] Set up backup procedures
- [ ] Configure monitoring
- [ ] Test query performance

### **Testing**
- [ ] Unit tests for services
- [ ] Integration tests for APIs
- [ ] E2E tests for user flows
- [ ] Performance testing
- [ ] Load testing

---

## üìã **Maintenance & Updates**

### **Regular Tasks**
- Monitor query performance
- Update grammar patterns as new textbook versions are released
- Validate relationship accuracy
- Review user feedback for improvements

### **Future Enhancements**
- Add more textbook series (Genki, Minna no Nihongo, etc.)
- Implement machine learning for personalized recommendations
- Add voice recognition for pronunciation practice
- Integrate with spaced repetition system
- Add gamification elements

---

## üéØ **Success Metrics**

### **Technical Metrics**
- Query response time < 100ms for common operations
- 99.9% uptime for grammar services
- < 2MB memory usage per user session
- Support for 1000+ concurrent users

### **Learning Metrics**
- Grammar pattern completion rates
- Learning path effectiveness
- User engagement with similar patterns
- Vocabulary-grammar connection usage

---

This comprehensive system provides a solid foundation for advanced Japanese grammar learning features in your AI Language Tutor application. The graph structure enables sophisticated AI-powered personalization while maintaining excellent performance and scalability.
